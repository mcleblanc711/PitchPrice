name: Scrape Hotel Rates

on:
  # Run twice weekly: Monday and Thursday at 6 AM UTC
  schedule:
    - cron: '0 6 * * 1'  # Monday 6 AM UTC
    - cron: '0 6 * * 4'  # Thursday 6 AM UTC

  # Allow manual triggering
  workflow_dispatch:
    inputs:
      cities:
        description: 'Cities to scrape (comma-separated: toronto,vancouver or leave empty for all)'
        required: false
        default: ''
      dry_run:
        description: 'Dry run (true/false)'
        required: false
        default: 'false'

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt
          playwright install chromium
          playwright install-deps chromium

      - name: Run scraper
        run: |
          cd scraper
          if [ -n "${{ github.event.inputs.cities }}" ]; then
            CITIES_ARG="--cities $(echo ${{ github.event.inputs.cities }} | tr ',' ' ')"
          else
            CITIES_ARG=""
          fi

          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            python scraper.py $CITIES_ARG --dry-run
          else
            python scraper.py $CITIES_ARG
          fi

      - name: Commit and push results
        if: github.event.inputs.dry_run != 'true'
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          # Add all data files
          git add data/

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Scrape data: $(date -u +'%Y-%m-%d %H:%M UTC')"
            git push
          fi

      - name: Upload scrape logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-logs-${{ github.run_id }}
          path: data/scrapes/
          retention-days: 30
